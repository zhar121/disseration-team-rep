# -*- coding: utf-8 -*-
"""Gutman+ML.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1TK76-6nbyxUnhFJngLv7BVx4EeEHy1SK
"""

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns

!gdown 1_HoZJ1rKCga2BT40f7hxc1L17KMBN9rW

df = pd.read_csv('data5 (3).csv')

df.shape

df.head()

unique_candidate_count = df['answerSheetId'].nunique()

print(f"Number of unique answerSheetId in the DataFrame: {unique_candidate_count}")

def calculate_guttman_error(df):
    # Initialize the Guttman error column
    df['guttmanError'] = 0

    # Iterate through each group (e.g., each candidate and their answers)
    for _, group in df.groupby(['candidateId', 'answerSheetId']):
        errors = []
        incorrect_found = False
        incorrect_index = -1
        for index, row in group.iterrows():
            if row['answeredCorrectly'] == 0:
                if incorrect_found:
                    # Update all correct responses after the last incorrect one
                    errors[incorrect_index:] = [x + 1 for x in errors[incorrect_index:]]
                incorrect_found = True
                incorrect_index = len(errors)
                errors.append(0)
            else:
                errors.append(0)

        # Place the computed errors back into the DataFrame
        df.loc[group.index, 'guttmanError'] = errors

    return df

# Calculate Guttman errors
df = calculate_guttman_error(df)

def calculate_guttman_score(df):
    # Ensure 'total_items' is correctly computed if not already in the DataFrame
    if 'total_items' not in df.columns:
        df['total_items'] = df.groupby(['candidateId', 'answerSheetId'])['questionId'].transform('count')
    if 'number_correct' not in df.columns:
        df['number_correct'] = df.groupby(['candidateId', 'answerSheetId'])['answeredCorrectly'].transform('sum')

    # Compute the Guttman score (G*), avoiding division by zero
    df['guttmanScore'] = df.apply(lambda x: x['guttmanError'] / (x['number_correct'] * (x['total_items'] - x['number_correct']))
                                  if x['number_correct'] * (x['total_items'] - x['number_correct']) != 0 else 0, axis=1)

    return df

# Assuming the DataFrame 'df' is already defined and loaded with necessary data

# Calculate Guttman scores
df = calculate_guttman_score(df)

# View or export results
print(df[['candidateId', 'answerSheetId', 'guttmanScore', 'guttmanError']])

df

def calculate_p_value_distance(df):
    # Calculate p-value distance based on the difficulty difference between consecutive questions
    df = df.sort_values(by=['candidateId', 'answerSheetId', 'firstSeenAt'])  # Ensure the data is sorted
    df['p_value_distance'] = df.groupby(['candidateId', 'answerSheetId'])['Difficulty'].diff().abs().fillna(0)
    return df

def calculate_work_pace(df):
    # Calculate average observed response time per item
    df['averageObservedTime'] = df.groupby(['candidateId', 'answerSheetId'])['ResponseTime'].transform('mean')
    # Calculate average expected response time per item (could be static or calculated from historical data)
    df['averageExpectedTime'] = df.groupby(['candidateId', 'answerSheetId'])['Expected response time'].transform('mean')
    # Calculate work pace
    df['workPace'] = df['averageObservedTime'] / df['averageExpectedTime']
    return df

# Function to calculate Guttman Score corrected for distance (G*d)
def calculate_guttman_score_distance(df, distance_type='positions'):
    # Assuming 'distance' is calculated or set outside this function
    df['distance'] = df.groupby(['candidateId', 'answerSheetId']).cumcount() + 1  # Example for position distance

    if distance_type == 'p_value':
        # Placeholder for p-value distance calculation
        df['distance'] = df['Difficulty']  # Example if Difficulty column represents p-value

    df['guttmanScoreDistance'] = df.apply(
        lambda x: x['guttmanError'] / (x['number_correct'] * (x['total_items'] - x['number_correct']) * x['distance'])
        if x['number_correct'] * (x['total_items'] - x['number_correct']) * x['distance'] != 0 else 0,
        axis=1
    )
    return df

# Function to calculate Guttman Score corrected for response time (G*rt)
def calculate_guttman_score_response_time(df):
    df['responseTimeDeviation'] = (df['workPace'] * df['Expected response time'] - df['ResponseTime']) / (df['workPace'] * df['Expected response time'])

    df['guttmanScoreResponseTime'] = df.apply(
        lambda x: x['guttmanError'] / (x['number_correct'] * (x['total_items'] - x['number_correct']) * abs(x['responseTimeDeviation']))
        if x['number_correct'] * (x['total_items'] - x['number_correct']) * abs(x['responseTimeDeviation']) != 0 else 0,
        axis=1
    )
    return df

# Function to calculate Guttman Score corrected for response time and distance (G*rtd)
def calculate_guttman_score_response_time_distance(df):
    df['guttmanScoreResponseTimeDistance'] = df.apply(
        lambda x: x['guttmanError'] / (x['number_correct'] * (x['total_items'] - x['number_correct']) * x['distance'] * abs(x['responseTimeDeviation']))
        if x['number_correct'] * (x['total_items'] - x['number_correct']) * x['distance'] * abs(x['responseTimeDeviation']) != 0 else 0,
        axis=1
    )
    return df

# Calculate work pace first to ensure 'workPace' column is added
df = calculate_work_pace(df)

# Calculate Guttman scores with distance corrections
df = calculate_guttman_score_distance(df, distance_type='positions')  # or 'p_value' for p-value based distance

# Calculate Guttman scores with response time corrections
df = calculate_guttman_score_response_time(df)

# Calculate combined corrections for Guttman scores
df = calculate_guttman_score_response_time_distance(df)

df

df.columns

from sklearn.ensemble import IsolationForest

# Assuming the dataset df is already loaded and processed as described previously

# Define the features to be used for anomaly detection
features = ['Z2', 'KL', 'KS', 'guttmanError', 'guttmanScore', 'guttmanScoreDistance', 'guttmanScoreResponseTime', 'guttmanScoreResponseTimeDistance']

# Drop rows with NaN in the relevant columns
df_clean = df.dropna(subset=features)

# Initialize Isolation Forest
clf = IsolationForest(contamination=0.01)  # Assuming 1% of the data is anomalous

# Fit the model and predict anomalies
df_clean['anomaly'] = clf.fit_predict(df_clean[features])

# Extract potential cheaters (anomalies) using Isolation Forest
potential_cheaters_ml = df_clean[df_clean['anomaly'] == -1]

# Count unique answerSheetId in the identified cheaters using Isolation Forest
unique_candidate_cheaters_ml = potential_cheaters_ml['answerSheetId'].nunique()
print(f"Number of unique potential cheaters identified by Isolation Forest: {unique_candidate_cheaters_ml}")

# Optionally, if you need to further filter out based on other criteria or thresholds:
potential_cheaters_ml_filtered = potential_cheaters_ml.groupby('answerSheetId').filter(lambda x: len(x) > 1)

# Count unique answerSheetId after additional filtering
unique_candidate_cheaters_ml_filtered = potential_cheaters_ml_filtered['answerSheetId'].nunique()
print(f"Number of unique potential cheated answersheets identified by Isolation Forest after filtering: {unique_candidate_cheaters_ml_filtered}")

# Extract unique candidate IDs
unique_candidate_cheaters_ml_filtered_ids = potential_cheaters_ml_filtered['answerSheetId'].unique()

filtered_cheater_ids = potential_cheaters_ml_filtered['answerSheetId'].unique()
print("Filtered Cheater IDs:", len(filtered_cheater_ids))

# save filtered_cheater_ids

from sklearn.cluster import KMeans
from sklearn.preprocessing import StandardScaler

# Standardize the data
scaler = StandardScaler()
scaled_features = scaler.fit_transform(df_clean[features])

# Determine optimal number of clusters using the elbow method
inertia = []
for n in range(1, 10):
    kmeans = KMeans(n_clusters=n, random_state=42, n_init=10)
    kmeans.fit(scaled_features)
    inertia.append(kmeans.inertia_)

plt.plot(range(1, 10), inertia, marker='o')
plt.xlabel('Number of clusters')
plt.ylabel('Inertia')
plt.title('Elbow Method for Optimal Clusters')
plt.show()

from sklearn.cluster import KMeans

# Based on the elbow method, we choose cluster 3 or 4
optimal_clusters = 3

# K-Means Clustering
kmeans = KMeans(n_clusters=optimal_clusters, random_state=42, n_init=10)
kmeans_labels = kmeans.fit_predict(scaled_features)

# Add cluster labels to the dataframe
df_clean['cluster'] = kmeans_labels

cluster_summary = df_clean.groupby('cluster').agg({
    'guttmanScore': ['mean', 'std'],
    'guttmanScoreDistance': ['mean', 'std'],
    'guttmanScoreResponseTime': ['mean', 'std'],
    'guttmanScoreResponseTimeDistance': ['mean', 'std'],
    'guttmanError': ['mean', 'std'],
    'Z2': ['mean', 'std'],
    'KL': ['mean', 'std'],
    'KS': ['mean', 'std']
})
print(cluster_summary)

"""Cluster 2 stands out with significantly higher values for guttmanScoreResponseTime and guttmanScoreResponseTimeDistance, indicating it is very different from the other clusters. Since it contains a single data point, this cluster is most likely the outlier."""

# Visualise clusters
plt.scatter(df_clean['Z2'], df_clean['KL'], c=kmeans_labels, cmap='viridis')
plt.xlabel('Z2')
plt.ylabel('KL')
plt.title('K-Means Clustering')
plt.show()

# Identify a specific cluster if cheating behavior is suspected in it
specific_cluster = 2  # Reason above

# Identifying potential cheaters
potential_cheaters_clusters = df_clean[df_clean['cluster'] == specific_cluster]

# Count unique answerSheetId in the identified cheaters using clustering
unique_candidate_cheaters_clusters_ids = potential_cheaters_clusters['answerSheetId'].unique()
print(f"Number of unique potential cheating answersheets identified by Clustering: {len(unique_candidate_cheaters_clusters_ids)}")

# Display unique answerSheetId and corresponding candidateId
unique_cheaters_info = potential_cheaters_clusters[['answerSheetId', 'candidateId']].drop_duplicates()
print("Unique potential cheating answersheets and corresponding candidates identified by Clustering:")
print(unique_cheaters_info)

from sklearn.cluster import KMeans

# Based on the elbow method, we choose cluster 3 or 4. We tried with k=3, now lets validate results with K=4
optimal_clusters = 4

# K-Means Clustering
kmeans = KMeans(n_clusters=optimal_clusters, random_state=42, n_init=10)
kmeans_labels = kmeans.fit_predict(scaled_features)

# Add cluster labels to the dataframe
df_clean['cluster'] = kmeans_labels

cluster_summary = df_clean.groupby('cluster').agg({
    'guttmanScore': ['mean', 'std'],
    'guttmanScoreDistance': ['mean', 'std'],
    'guttmanScoreResponseTime': ['mean', 'std'],
    'guttmanScoreResponseTimeDistance': ['mean', 'std'],
    'guttmanError': ['mean', 'std'],
    'Z2': ['mean', 'std'],
    'KL': ['mean', 'std'],
    'KS': ['mean', 'std']
})
print(cluster_summary)

"""Analyzing the statistics provided for clusters 0 through 3, it's evident that Cluster 3 stands out significantly in a similar manner to previous analysis, indicating potential anomalies."""

# Identify a specific cluster if cheating behavior is suspected in it
specific_cluster = 3  # Reason above

# Identifying potential cheaters
potential_cheaters_clusters = df_clean[df_clean['cluster'] == specific_cluster]

# Count unique answerSheetId in the identified cheaters using clustering
unique_candidate_cheaters_clusters_ids = potential_cheaters_clusters['answerSheetId'].unique()
print(f"Number of unique potential cheating answersheets identified by Clustering: {len(unique_candidate_cheaters_clusters_ids)}")

# Display unique answerSheetId and corresponding candidateId
unique_cheaters_info = potential_cheaters_clusters[['answerSheetId', 'candidateId']].drop_duplicates()
print("Unique potential cheating answersheets and corresponding candidates identified by Clustering:")
print(unique_cheaters_info)

# Validating the number of optimal clusters using Silhouette Method
import numpy as np
import pandas as pd
from sklearn.metrics import silhouette_score
from sklearn.cluster import KMeans
import matplotlib.pyplot as plt


# Define the features to be used for anomaly detection
features = ['Z2', 'KL', 'KS', 'guttmanError', 'guttmanScore', 'guttmanScoreDistance', 'guttmanScoreResponseTime', 'guttmanScoreResponseTimeDistance']

# Drop rows with NaN in the relevant columns
df_clean = df.dropna(subset=features)

# Use only the defined features for clustering
X = df_clean[features]

# Range of clusters to test
range_n_clusters = list(range(2, 10))  # Usually, start with 2 to an upper limit that makes sense for your dataset

silhouette_avg_scores = []

for num_clusters in range_n_clusters:
    kmeans = KMeans(n_clusters=num_clusters, random_state=42)
    cluster_labels = kmeans.fit_predict(X)  # X is now the dataset limited to specified features

    silhouette_avg = silhouette_score(X, cluster_labels)
    silhouette_avg_scores.append(silhouette_avg)
    print(f"For n_clusters = {num_clusters}, the average silhouette_score is: {silhouette_avg}")

# Plot silhouette scores
plt.plot(range_n_clusters, silhouette_avg_scores, marker='o')
plt.xlabel('Number of Clusters')
plt.ylabel('Average Silhouette Score')
plt.title('Silhouette Analysis For Optimal Clusters')
plt.show()

optimal_clusters = 4  # Number chosen from silhouette analysis
kmeans = KMeans(n_clusters=optimal_clusters, random_state=42)
final_cluster_labels = kmeans.fit_predict(X)

# Add cluster information to the DataFrame
df['cluster'] = final_cluster_labels

# Analyze clusters
for i in range(optimal_clusters):
    cluster_data = df[df['cluster'] == i]
    print(f"Analysis for Cluster {i}:")
    print(cluster_data.describe())  # Or any other statistical summary or plots

    # Count unique AnswerSheetIds in the cluster
    unique_answer_sheets = cluster_data['answerSheetId'].nunique()
    print(f"Number of unique AnswerSheetIds in Cluster {i}: {unique_answer_sheets}")

    # Count unique CandidateIds in the cluster
    unique_candidates = cluster_data['candidateId'].nunique()
    print(f"Number of unique CandidateIds in Cluster {i}: {unique_candidates}")

# Visualize comparison between clusters using box plots for each feature
for feature in features:
    plt.figure(figsize=(10, 6))
    sns.boxplot(x='cluster', y=feature, data=df)
    plt.title(f'Comparison of {feature} Across Clusters')
    plt.show()

# Ensure the DataFrame contains the required columns
if 'Z2' in df.columns and 'guttmanScore' in df.columns and 'cluster' in df.columns:
    # Create a scatter plot
    plt.figure(figsize=(10, 6))
    sns.scatterplot(x='Z2', y='guttmanScore', hue='cluster', data=df, palette='Set1')
    plt.title('Scatter Plot between Z2 and gutmanScore')
    plt.xlabel('Z2')
    plt.ylabel('gutmanScore')
    plt.legend(title='Cluster')
    plt.show()
else:
    print("The DataFrame does not contain the required columns.")

suspicious_cluster = 1  # Cluster identified for further investigation

# Filter the data to get entries from the suspicious cluster
suspicious_data = df[df['cluster'] == suspicious_cluster]

# Check if there is suspicious data and print it
if not suspicious_data.empty:
    print("Suspicious Answer Sheet IDs and Corresponding Candidate IDs:")
    # Ensure 'AnswerSheetId' and 'CandidateId' are the actual column names in your DataFrame
    print(suspicious_data[['answerSheetId', 'candidateId']])
else:
    print("No data found for the specified cluster.")

# Display the list of unique candidate IDs
print("List of unique potential cheaters identified by Clustering:")
for candidate_id in unique_candidate_cheaters_clusters_ids:
    print(candidate_id)



# Combine results from Isolation Forest and Clustering
combined_cheaters = set(unique_candidate_cheaters_ml_filtered_ids).intersection(set(unique_candidate_cheaters_clusters_ids))

print(f"Total unique potential cheaters identified: {len(combined_cheaters)}")

# Display the list of unique candidate IDs
print("List of common potential cheaters identified by both the methods")
for candidate_id in combined_cheaters:
    print(candidate_id)

from sklearn.cluster import DBSCAN

# Apply DBSCAN
dbscan = DBSCAN(eps=0.8, min_samples=2)
dbscan_labels = dbscan.fit_predict(scaled_features)

# Add cluster labels to the dataframe
df_clean['dbscan_cluster'] = dbscan_labels

# Identify potential cheaters (assuming -1 label for noise/outliers in DBSCAN)
potential_cheaters_dbscan = df_clean[df_clean['dbscan_cluster'] == -1]

# Count unique answerSheetId in the identified cheaters using DBSCAN
unique_candidate_cheaters_dbscan_ids = potential_cheaters_dbscan['answerSheetId'].unique()

print(f"Number of unique potential cheaters identified by DBSCAN: {len(unique_candidate_cheaters_dbscan_ids)}")

print("Candidate IDs of potential cheaters identified by DBSCAN:", unique_candidate_cheaters_dbscan_ids)

# Print the results
print(f"Number of unique potential cheating answerSheetIds identified by Isolation Forest: {len(unique_candidate_cheaters_ml_filtered_ids)}")

print(f"Number of unique potential cheating answerSheetIds identified by K-Means Clustering: {len(unique_candidate_cheaters_clusters_ids)}")

print(f"Number of unique potential cheating answerSheetIds identified by DBSCAN: {len(unique_candidate_cheaters_dbscan_ids)}")

print(unique_candidate_cheaters_ml_filtered_ids)

# make unique_candidate_cheaters_ml_filtered_ids as dataframe with colunmn name = 'answerSheetId'
unique_candidate_cheaters_ml_filtered_ids_df = pd.DataFrame(unique_candidate_cheaters_ml_filtered_ids, columns=['answerSheetId'])
# save df to csv
unique_candidate_cheaters_ml_filtered_ids_df.to_csv('unique_candidate_cheaters_ml_filtered_ids_df.csv', index=False)

unique_candidate_cheaters_ml_filtered_ids_df.shape

unique_candidate_cheaters_clusters_ids_df = pd.DataFrame(unique_candidate_cheaters_clusters_ids, columns=['answerSheetId'])
# save df to csv
unique_candidate_cheaters_clusters_ids_df.to_csv('unique_candidate_cheaters_clusters_ids_df.csv', index=False)

unique_candidate_cheaters_clusters_ids_df.shape

unique_candidate_cheaters_dbscan_ids_df = pd.DataFrame(unique_candidate_cheaters_dbscan_ids, columns=['answerSheetId'])
# save df to csv
unique_candidate_cheaters_dbscan_ids_df.to_csv('unique_candidate_cheaters_dbscan_ids_df.csv', index=False)

# Combine results from Isolation Forest, K-Means, and DBSCAN
combined_cheaters = set(unique_candidate_cheaters_ml_filtered_ids).union(
    set(unique_candidate_cheaters_clusters_ids), set(unique_candidate_cheaters_dbscan_ids))

# Find common cheaters among the three methods
common_cheaters = set(unique_candidate_cheaters_ml_filtered_ids).intersection(
    set(unique_candidate_cheaters_clusters_ids), set(unique_candidate_cheaters_dbscan_ids))

print(f"Total unique potential cheating answerSheetIds identified: {len(combined_cheaters)}")
print(f"Number of common potential cheating answerSheetIds identified by all three methods: {len(common_cheaters)}")

# Get candidateIds from df where answerSheetId = combined_cheaters
candidate_ids = df[df['answerSheetId'].isin(combined_cheaters)]['candidateId'].unique()
print("Candidate IDs of potential cheaters identified by all three methods:", len(candidate_ids))

# Print table of cheating answerSheetIds and candidateIds
print("Cheating answerSheetIds and candidateIds:")

unique_pairs = df[df['answerSheetId'].isin(combined_cheaters)][['answerSheetId', 'candidateId']].drop_duplicates()

# Save unique_pairs as Excel file
unique_pairs.to_excel('unique_pairs.xlsx', index=False)

print("Candidate IDs of common potential cheaters identified by all three methods:", common_cheaters)